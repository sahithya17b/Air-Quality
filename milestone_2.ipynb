{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7m7d0q8qnMPn1EEYLn1fh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahithya17b/Air-Quality/blob/main/milestone_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxpUl_c5CM4M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/air quality original.csv\" # ðŸ”¹ change this to your file path\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXZ5IrwGCXrx",
        "outputId": "96d2aab4-17f0-4043-8b30-d68a0a6906d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1573052410.py:2: DtypeWarning: Columns (3,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Data:\\n\", df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8QDC6vQDHji",
        "outputId": "b5ff654b-90e7-4569-d8b9-5203b17d3127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "                date   sitename          county aqi pollutant    status  so2  \\\n",
            "0  31-08-2024 23:00      Hukou  Hsinchu County  62     PM2.5  Moderate  0.9   \n",
            "1  31-08-2024 23:00  Zhongming   Taichung City  50       NaN      Good  1.6   \n",
            "2  31-08-2024 23:00    Zhudong  Hsinchu County  45       NaN      Good  0.4   \n",
            "3  31-08-2024 23:00    Hsinchu    Hsinchu City  42       NaN      Good  0.8   \n",
            "4  31-08-2024 23:00     Toufen   Miaoli County  50       NaN      Good    1   \n",
            "\n",
            "     co    o3 o3_8hr  ...   no windspeed winddirec co_8hr pm2.5_avg pm10_avg  \\\n",
            "0  0.17    35   40.2  ...  0.3       2.3       225    0.2      20.1       26   \n",
            "1  0.32  27.9   35.1  ...  1.6       1.1       184    0.2      15.3       23   \n",
            "2  0.17  25.1   40.6  ...  1.1       0.4       210    0.2      13.8       24   \n",
            "3   0.2    30   35.9  ...  0.7       1.9       239    0.2        13       26   \n",
            "4  0.16  33.5   35.9  ...  1.2       1.8       259    0.1      15.3       28   \n",
            "\n",
            "  so2_avg    longitude     latitude siteid  \n",
            "0       1  121.0388689  24.90009696     22  \n",
            "1       1   120.641092    24.151958     31  \n",
            "2       0  121.0889549  24.74091408     23  \n",
            "3       1  120.9723675   24.8056356     24  \n",
            "4       1  120.8986929  24.69690679     25  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "2zn8P9Q2Da3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(how='all')"
      ],
      "metadata": {
        "id": "Qboy-drPDgih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace(r'^\\s*$', pd.NA, regex=True)"
      ],
      "metadata": {
        "id": "5zrrpwa6DmGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    try:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    except:\n",
        "        pass  # skip non-numeric columns safely"
      ],
      "metadata": {
        "id": "Kay3S0gIDr1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "    if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
        "        # numeric columns â†’ use mean\n",
        "        df[col] = df[col].fillna(df[col].mean())\n",
        "    else:\n",
        "        # categorical/text columns â†’ use mode\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n"
      ],
      "metadata": {
        "id": "QBDbJxouD2Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCleaned Data:\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MUGhav-D64H",
        "outputId": "e96a3052-d774-4c62-99d3-6abccc880b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned Data:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save cleaned dataset (optional)\n",
        "df.to_csv(\"cleaned_dataset.csv\", index=False)\n",
        "print(\"\\nâœ… Cleaned dataset saved as 'cleaned_dataset.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKb7V1l6D9UQ",
        "outputId": "32a3415b-2848-4085-8333-3ab9dbf7dccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Cleaned dataset saved as 'cleaned_dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File path\n",
        "file_path = \"/mnt/data/dataset_extracted/air_quality.csv\"\n",
        "cleaned_file_path = \"/mnt/data/air_quality_cleaned.csv\"\n",
        "\n",
        "# Step 1: Read dataset in chunks\n",
        "chunks = pd.read_csv(file_path, low_memory=False, chunksize=50000)\n",
        "\n",
        "# Step 2: Process each chunk\n",
        "cleaned_chunks = []\n",
        "for chunk in chunks:\n",
        "    # Remove duplicates inside the chunk\n",
        "    chunk = chunk.drop_duplicates()\n",
        "\n",
        "    # Replace empty strings with NaN\n",
        "    chunk = chunk.replace(r'^\\s*$', pd.NA, regex=True)\n",
        "\n",
        "    # Drop rows that are completely blank\n",
        "    chunk = chunk.dropna(how='all')\n",
        "\n",
        "    cleaned_chunks.append(chunk)\n",
        "\n",
        "# Step 3: Concatenate all cleaned chunks\n",
        "df = pd.concat(cleaned_chunks, ignore_index=True)\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "numeric_cols = df.select_dtypes(include=['float64','int64']).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Fill numeric columns with median\n",
        "for col in numeric_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# Fill categorical columns with mode\n",
        "for col in categorical_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "# Step 5: Save cleaned dataset\n",
        "df.to_csv(cleaned_file_path, index=False)\n",
        "\n",
        "print(\"âœ… Cleaning complete. Cleaned dataset saved at:\", cleaned_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "VMEbWjj0Ho9V",
        "outputId": "ec62ff9b-b2f2-410f-bcc8-136d2df628c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/mnt/data/dataset_extracted/air_quality.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3043391600.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Step 1: Read dataset in chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Step 2: Process each chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/dataset_extracted/air_quality.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File path\n",
        "file_path = \"/content/air_quality.csv\"\n",
        "cleaned_file_path = \"/content/cleaned_dataset.csv\""
      ],
      "metadata": {
        "id": "XlpxT5M3Hv5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = pd.read_csv(file_path, low_memory=False, chunksize=50000)\n"
      ],
      "metadata": {
        "id": "Je5b9A2mH6QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_chunks = []\n",
        "for chunk in chunks:\n",
        "    # Remove duplicates inside the chunk\n",
        "    chunk = chunk.drop_duplicates()\n",
        "\n",
        "    # Replace empty strings with NaN\n",
        "    chunk = chunk.replace(r'^\\s*$', pd.NA, regex=True)\n",
        "\n",
        "    # Drop rows that are completely blank\n",
        "    chunk = chunk.dropna(how='all')\n",
        "\n",
        "    cleaned_chunks.append(chunk)"
      ],
      "metadata": {
        "id": "nnLAxzdgIcRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat(cleaned_chunks, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "4uM74G2fI1AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df.select_dtypes(include=['float64','int64']).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()"
      ],
      "metadata": {
        "id": "n1V5l_IkI_qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numeric_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# Fill categorical columns with mode\n",
        "for col in categorical_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])"
      ],
      "metadata": {
        "id": "PByJW3qkJI8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(cleaned_file_path, index=False)\n",
        "\n",
        "print(\"âœ… Cleaning complete. Cleaned dataset saved at:\", cleaned_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvme8XQeJWWk",
        "outputId": "464f93de-3e8e-48e8-b743-806adccd9075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cleaning complete. Cleaned dataset saved at: /content/cleaned_dataset.csv\n"
          ]
        }
      ]
    }
  ]
}