{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQG2aB6SRvRSSC+WPIF0gA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahithya17b/Air-Quality/blob/main/day_17_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWZuPIkpuhzJ"
      },
      "outputs": [],
      "source": [
        "#Main Categories of Machine Learning\n",
        "1. Supervised Learning\n",
        "\n",
        "Definition: The model is trained on a labeled dataset (inputs + correct outputs).\n",
        "\n",
        "Goal: Learn a mapping from inputs (X) ‚Üí outputs (Y).\n",
        "\n",
        "Applications: Spam detection, price prediction, image classification.\n",
        "\n",
        "üìò Types:\n",
        "\n",
        "Regression (predicting continuous values)\n",
        "\n",
        "Classification (predicting discrete classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#| Type               | Algorithm                       | Description                                           |\n",
        "| ------------------ | ------------------------------- | ----------------------------------------------------- |\n",
        "| **Regression**     | Linear Regression               | Fits a straight line between input and output.        |\n",
        "|                    | Polynomial Regression           | Models nonlinear relationships.                       |\n",
        "|                    | Decision Tree Regressor         | Splits data into regions to predict values.           |\n",
        "|                    | Random Forest Regressor         | Ensemble of multiple decision trees.                  |\n",
        "|                    | Support Vector Regression (SVR) | Uses margin-based approach for regression.            |\n",
        "|                    | Neural Networks (ANN)           | Learns complex nonlinear relationships.               |\n",
        "| **Classification** | Logistic Regression             | For binary classification problems.                   |\n",
        "|                    | K-Nearest Neighbors (KNN)       | Classifies based on nearest data points.              |\n",
        "|                    | Decision Tree Classifier        | Tree structure to classify data.                      |\n",
        "|                    | Random Forest Classifier        | Ensemble of decision trees.                           |\n",
        "|                    | Support Vector Machine (SVM)    | Finds best hyperplane separating classes.             |\n",
        "|                    | Naive Bayes                     | Based on Bayes‚Äô theorem with independence assumption. |\n",
        "|                    | Neural Networks (ANN, CNN, RNN) | Deep learning models for complex classification.      |\n"
      ],
      "metadata": {
        "id": "T57RSK2mwqKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Unsupervised Learning\n",
        "\n",
        "Definition: Data is unlabeled ‚Äî the model finds hidden patterns or groupings.\n",
        "\n",
        "Goal: Discover structure or reduce dimensionality.\n",
        "\n",
        "Applications: Customer segmentation, anomaly detection, topic modeling.\n",
        "\n",
        "üìò Types:\n",
        "\n",
        "Clustering\n",
        "\n",
        "Association\n",
        "\n",
        "Dimensionality Reduction"
      ],
      "metadata": {
        "id": "FS2XXrV0wvPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#| Type                         | Algorithm                          | Description                                             |\n",
        "| ---------------------------- | ---------------------------------- | ------------------------------------------------------- |\n",
        "| **Clustering**               | K-Means                            | Divides data into *k* clusters.                         |\n",
        "|                              | Hierarchical Clustering            | Builds a tree of clusters.                              |\n",
        "|                              | DBSCAN                             | Groups points based on density.                         |\n",
        "| **Association**              | Apriori                            | Finds association rules (e.g., market basket analysis). |\n",
        "|                              | Eclat                              | Faster association rule mining method.                  |\n",
        "| **Dimensionality Reduction** | PCA (Principal Component Analysis) | Reduces feature space while keeping variance.           |\n",
        "|                              | t-SNE                              | Nonlinear reduction for visualization.                  |\n",
        "|                              | Autoencoders                       | Neural networks for dimensionality reduction.           |\n"
      ],
      "metadata": {
        "id": "Lj7WnFYyutbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#. Semi-Supervised Learning\n",
        "\n",
        "Definition: Uses both labeled and unlabeled data (often small labeled + large unlabeled).\n",
        "\n",
        "Goal: Improve learning accuracy when labeled data is scarce.\n",
        "\n",
        "Applications: Speech recognition, web content classification.\n",
        "\n",
        "‚öôÔ∏è Common Algorithms:\n",
        "\n",
        "Self-training\n",
        "\n",
        "Label Propagation\n",
        "\n",
        "Semi-Supervised SVM\n",
        "\n",
        "Generative Models (e.g., Variational Autoencoders)\n",
        "\n",
        "4. Reinforcement Learning (RL)\n",
        "\n",
        "Definition: The model learns by interacting with the environment through trial and error.\n",
        "\n",
        "Goal: Maximize cumulative reward.\n",
        "\n",
        "Applications: Game playing, robotics, self-driving cars.\n",
        "\n",
        "üìò Types:\n",
        "\n",
        "Positive / Negative Reinforcement\n",
        "\n",
        "Model-based / Model-free RL"
      ],
      "metadata": {
        "id": "NdE72XsJw-Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#| Algorithm               | Description                                                      |\n",
        "| ----------------------- | ---------------------------------------------------------------- |\n",
        "| Q-Learning              | Learns value of actions in a given state.                        |\n",
        "| SARSA                   | Similar to Q-learning but updates based on actual actions taken. |\n",
        "| Deep Q-Networks (DQN)   | Combines Q-learning with deep neural networks.                   |\n",
        "| Policy Gradient Methods | Directly optimize the policy.                                    |\n",
        "| Actor-Critic Methods    | Combines value-based and policy-based approaches.                |\n"
      ],
      "metadata": {
        "id": "REzBakE5xCFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Self-Supervised Learning (Emerging)\n",
        "\n",
        "Definition: The model creates its own labels from the input data itself (subset of unsupervised).\n",
        "\n",
        "Applications: Natural Language Processing (e.g., GPT), Vision models.\n",
        "\n",
        "‚öôÔ∏è Common Algorithms:\n",
        "\n",
        "Contrastive Learning (SimCLR, MoCo)\n",
        "\n",
        "Masked Autoencoders (MAE)\n",
        "\n",
        "Transformers (BERT, GPT)"
      ],
      "metadata": {
        "id": "WZgtKXe9xHqQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}